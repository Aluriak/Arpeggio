{
    "docs": [
        {
            "location": "/",
            "text": "Arpeggio is recursive descent parser with backtracking and memoization (a.k.a.\npacrat parser).  Arpeggio grammars are based on \nPEG\nformalism\n.\n\n\nArpeggio's main use is a foundation for a tool-chain for DSL development but it\ncan be used for all sort of general purpose parsing.\n\n\nFor more information on PEG and packrat parsers see \nthis\npage\n.\n\n\nFor a higher level library for building DSLs take a look at\n\ntextX\n. It builds on top of Arpeggio\nand makes language parser implementation a lot easier.\n\n\nSee \nGetting started\n in the \nUser Guide\n menu to get you going or read some of the\ntutorials.\n\n\nFeatures\n\n\n\n\nUsing \nParsing Expression Grammar\n\n  and packrat parsing - unambiguous grammars, unlimited lookahead, linear time.\n\n\nWorks as grammar interpreter - no code is generated.\n\n\nMultiple syntaxes for grammar definition (\nPython\n, \n  \npeg, cleanpeg\n, make your own)\n\n\nCase sensitive/insensitive\n  parsing\n\n\nWhitespace handling control\n\n\nKeyword handling\n\n\nSupport for comments\n\n\nNewline termination for\n  Repetition\n (available only in Python syntax)\n\n\nParse tree navigation\n\n\nVisitors for semantic analysis\n\n\nExtensive error reporting\n\n\nGood support for debugging and visualization\n\n\nGood test coverage\n\n\nBeautiful mkdocs documentation - you are reading it\n\n\n\n\nOpen-source projects using Arpeggio\n\n\n\n\ntextX\n - Meta-language for building\n  Domain-Specific Languages in Python (and all projects using textX)\n\n\nwhatami\n - Unobtrusive object\n  self-identification for Python\n  (\nparsers\n\n  module)\n\n\n\n\nWhy is it called arpeggio?\n\n\nIn music, arpeggio is playing the chord notes one by one in sequence. I came up\nwith the name by thinking that parsing is very similar to arpeggios in music.\nYou take tokens one by one from an input and make sense out of it \u2013 make a\nchord!\n\n\nWell, if you don't buy this maybe it is time to tell you the truth. I searched\nthe dictionary for the words that contain PEG acronym and the word arpeggio was\nat the top of the list ;)",
            "title": "Home"
        },
        {
            "location": "/#features",
            "text": "Using  Parsing Expression Grammar \n  and packrat parsing - unambiguous grammars, unlimited lookahead, linear time.  Works as grammar interpreter - no code is generated.  Multiple syntaxes for grammar definition ( Python , \n   peg, cleanpeg , make your own)  Case sensitive/insensitive\n  parsing  Whitespace handling control  Keyword handling  Support for comments  Newline termination for\n  Repetition  (available only in Python syntax)  Parse tree navigation  Visitors for semantic analysis  Extensive error reporting  Good support for debugging and visualization  Good test coverage  Beautiful mkdocs documentation - you are reading it",
            "title": "Features"
        },
        {
            "location": "/#open-source-projects-using-arpeggio",
            "text": "textX  - Meta-language for building\n  Domain-Specific Languages in Python (and all projects using textX)  whatami  - Unobtrusive object\n  self-identification for Python\n  ( parsers \n  module)",
            "title": "Open-source projects using Arpeggio"
        },
        {
            "location": "/#why-is-it-called-arpeggio",
            "text": "In music, arpeggio is playing the chord notes one by one in sequence. I came up\nwith the name by thinking that parsing is very similar to arpeggios in music.\nYou take tokens one by one from an input and make sense out of it \u2013 make a\nchord!  Well, if you don't buy this maybe it is time to tell you the truth. I searched\nthe dictionary for the words that contain PEG acronym and the word arpeggio was\nat the top of the list ;)",
            "title": "Why is it called arpeggio?"
        },
        {
            "location": "/getting_started/",
            "text": "Getting started\n\n\nInstallation and your first steps with Arpeggio.\n\n\n\n\nInstallation\n\n\nArpeggio is written in Python programming language and distributed with\nsetuptools support. If you have \npip\n tool installed the most recent stable\nversion of Arpeggio can be installed form\n\nPyPI\n with the following command:\n\n\n    $ pip install Arpeggio\n\n\n\n\nTo verify that you have installed Arpeggio correctly run the following command:\n\n\n$ python -c 'import arpeggio'\n\n\n\n\nIf you get no error, Arpeggio is correctly installed.\n\n\nTo install Arpeggio for contribution see \nhere\n.\n\n\nInstalling from source\n\n\nIf for some weird reason you don't have or don't want to use \npip\n you can still\ninstall Arpeggio from source.\n\n\nTo download source distribution do:\n\n\n\n\n\n\ndownload\n\n\n$ wget https://github.com/igordejanovic/Arpeggio/archive/v1.1.tar.gz\n\n\n\n\n\n\n\nunpack\n\n\n$ tar xzf v1.1.tar.gz\n\n\n\n\n\n\n\ninstall\n\n\n$ cd Arpeggio-1.1\n$ python setup.py install\n\n\n\n\n\n\n\nQuick start\n\n\nBasic workflow in using Arpeggio goes like this:\n\n\nWrite \na grammar\n. There are several ways to do that:\n\n\n\n\n\n\nThe canonical grammar format\n uses\n  Python statements and expressions.  Each rule is specified as Python function\n  which should return a data structure that defines the rule. For example a\n  grammar for simple calculator can be written as:\n\n\nfrom arpeggio import Optional, ZeroOrMore, OneOrMore, EOF\nfrom arpeggio import RegExMatch as _\n\ndef number():     return _(r'\\d*\\.\\d*|\\d+')\ndef factor():     return Optional([\"+\",\"-\"]), [number, (\"(\", expression, \")\")]\ndef term():       return factor, ZeroOrMore([\"*\",\"/\"], factor)\ndef expression(): return term, ZeroOrMore([\"+\", \"-\"], term)\ndef calc():       return OneOrMore(expression), EOF\n\n\n\nThe python lists in the data structure represent ordered choices while the tuples represent sequences from the PEG.\nFor terminal matches use plain strings or regular expressions.\n\n\n\n\n\n\nThe same grammar could also be written using \ntraditional textual PEG\n  syntax\n like this:\n\n\nnumber <- r'\\d*\\.\\d*|\\d+';  // this is a comment\nfactor <- (\"+\" / \"-\")? (number / \"(\" expression \")\");\nterm <- factor (( \"*\" / \"/\") factor)*;\nexpression <- term ((\"+\" / \"-\") term)*;\ncalc <- expression+ EOF;\n\n\n\n\n\n\n\nOr similar syntax but a little bit more readable like this:\n\n\nnumber = r'\\d*\\.\\d*|\\d+'    # this is a comment\nfactor = (\"+\" / \"-\")? (number / \"(\" expression \")\")\nterm = factor (( \"*\" / \"/\") factor)*\nexpression = term ((\"+\" / \"-\") term)*\ncalc = expression+ EOF\n\n\n\nThe second and third options are implemented using canonical first form.\nFeel free to implement your own grammar syntax if you don't like these\n(see modules \narpeggio.peg\n and \narpeggio.cleanpeg\n).\n\n\n\n\n\n\nInstantiate a parser\n. Parser works as a grammar interpreter. There is no\ncode generation.\n\n\nfrom arpeggio import ParserPython\nparser = ParserPython(calc)   # calc is the root rule of your grammar\n                              # Use param debug=True for verbose debugging\n                              # messages and grammar and parse tree visualization\n                              # using graphviz and dot\n\n\n\n\nParse your inputs\n\n\nparse_tree = parser.parse(\"-(4-1)*5+(2+4.67)+5.89/(.2+7)\")\n\n\n\n\nIf parsing is successful (e.g. no syntax error if found) you get a \nparse\ntree\n.\n\n\nAnalyze parse tree\n directly or write a \nvisitor class\n to\ntransform it to a more usable form.\n\n\nFor \ntextual PEG syntaxes\n\ninstead of \nParserPyton\n instantiate \nParserPEG\n from \narpeggio.peg\n or\n\narpeggio.cleanpeg\n modules. See examples how it is done.\n\n\nTo \ndebug your grammar\n set \ndebug\n parameter to \nTrue\n. A verbose\ndebug messages will be printed and a dot files will be generated for parser\nmodel (grammar) and parse tree visualization.\n\n\nHere is an image rendered using graphviz of parser model for \ncalc\n grammar.\n\n\n\n\nAnd here is an image rendered for parse tree for the above parsed \ncalc\n expression.\n\n\n\n\nRead Tutorials\n\n\nRead some of the tutorials (\nCSV\n, \nBibTex\n,\n\nCalc\n).",
            "title": "Getting started"
        },
        {
            "location": "/getting_started/#getting-started",
            "text": "Installation and your first steps with Arpeggio.",
            "title": "Getting started"
        },
        {
            "location": "/getting_started/#installation",
            "text": "Arpeggio is written in Python programming language and distributed with\nsetuptools support. If you have  pip  tool installed the most recent stable\nversion of Arpeggio can be installed form PyPI  with the following command:      $ pip install Arpeggio  To verify that you have installed Arpeggio correctly run the following command:  $ python -c 'import arpeggio'  If you get no error, Arpeggio is correctly installed.  To install Arpeggio for contribution see  here .  Installing from source  If for some weird reason you don't have or don't want to use  pip  you can still\ninstall Arpeggio from source.  To download source distribution do:    download  $ wget https://github.com/igordejanovic/Arpeggio/archive/v1.1.tar.gz    unpack  $ tar xzf v1.1.tar.gz    install  $ cd Arpeggio-1.1\n$ python setup.py install",
            "title": "Installation"
        },
        {
            "location": "/getting_started/#quick-start",
            "text": "Basic workflow in using Arpeggio goes like this:  Write  a grammar . There are several ways to do that:    The canonical grammar format  uses\n  Python statements and expressions.  Each rule is specified as Python function\n  which should return a data structure that defines the rule. For example a\n  grammar for simple calculator can be written as:  from arpeggio import Optional, ZeroOrMore, OneOrMore, EOF\nfrom arpeggio import RegExMatch as _\n\ndef number():     return _(r'\\d*\\.\\d*|\\d+')\ndef factor():     return Optional([\"+\",\"-\"]), [number, (\"(\", expression, \")\")]\ndef term():       return factor, ZeroOrMore([\"*\",\"/\"], factor)\ndef expression(): return term, ZeroOrMore([\"+\", \"-\"], term)\ndef calc():       return OneOrMore(expression), EOF  The python lists in the data structure represent ordered choices while the tuples represent sequences from the PEG.\nFor terminal matches use plain strings or regular expressions.    The same grammar could also be written using  traditional textual PEG\n  syntax  like this:  number <- r'\\d*\\.\\d*|\\d+';  // this is a comment\nfactor <- (\"+\" / \"-\")? (number / \"(\" expression \")\");\nterm <- factor (( \"*\" / \"/\") factor)*;\nexpression <- term ((\"+\" / \"-\") term)*;\ncalc <- expression+ EOF;    Or similar syntax but a little bit more readable like this:  number = r'\\d*\\.\\d*|\\d+'    # this is a comment\nfactor = (\"+\" / \"-\")? (number / \"(\" expression \")\")\nterm = factor (( \"*\" / \"/\") factor)*\nexpression = term ((\"+\" / \"-\") term)*\ncalc = expression+ EOF  The second and third options are implemented using canonical first form.\nFeel free to implement your own grammar syntax if you don't like these\n(see modules  arpeggio.peg  and  arpeggio.cleanpeg ).    Instantiate a parser . Parser works as a grammar interpreter. There is no\ncode generation.  from arpeggio import ParserPython\nparser = ParserPython(calc)   # calc is the root rule of your grammar\n                              # Use param debug=True for verbose debugging\n                              # messages and grammar and parse tree visualization\n                              # using graphviz and dot  Parse your inputs  parse_tree = parser.parse(\"-(4-1)*5+(2+4.67)+5.89/(.2+7)\")  If parsing is successful (e.g. no syntax error if found) you get a  parse\ntree .  Analyze parse tree  directly or write a  visitor class  to\ntransform it to a more usable form.  For  textual PEG syntaxes \ninstead of  ParserPyton  instantiate  ParserPEG  from  arpeggio.peg  or arpeggio.cleanpeg  modules. See examples how it is done.  To  debug your grammar  set  debug  parameter to  True . A verbose\ndebug messages will be printed and a dot files will be generated for parser\nmodel (grammar) and parse tree visualization.  Here is an image rendered using graphviz of parser model for  calc  grammar.   And here is an image rendered for parse tree for the above parsed  calc  expression.",
            "title": "Quick start"
        },
        {
            "location": "/getting_started/#read-tutorials",
            "text": "Read some of the tutorials ( CSV ,  BibTex , Calc ).",
            "title": "Read Tutorials"
        },
        {
            "location": "/grammars/",
            "text": "Grammars\n\n\nWith grammar you teach Arpeggio how to parse your inputs.\n\n\n\n\nArpeggio is based on \nPEG grammars\n.\nPEG is a type of formal grammar that is given as a set of rules for recognizing\nstrings of the language.  In a way it is similar to context-free grammars with a\nvery important distinction that PEG are always unambiguous. This is achieved by\nmaking choice operator ordered. In PEGs a first choice from left to right that\nmatches will be used.\n\n\n\n\nNote\n\n\nMore information on PEGs can be found on \nthis page\n.\n\n\n\n\nPEG grammar is a set of PEG rules. PEG rules consists of parsing expressions and\ncan reference (call) each other.\n\n\nExample grammar in PEG notation:\n\n\nfirst = 'foo' second+ EOF\nsecond = 'bar' / 'baz'\n\n\n\nIn this example \nfirst\n is the root rule. This rule will match a literal\nstring \nfoo\n followed by one or more \nsecond\n rule (this is a rule\nreference) followed by end of input (\nEOF\n).  \nsecond\n rule is ordered\nchoice and will match either \nbar\n or \nbaz\n in that order.\n\n\nDuring parsing each successfully matched rule will create a parse tree node.  At\nthe end of parsing a complete \nparse tree\n of the input will be\nreturned.  .\n\n\nIn Arpeggio each PEG rule consists of atomic parsing expression which can be:\n\n\n\n\n\n\nterminal match rules\n - create a \nTerminal nodes\n:\n\n\n\n\nString match\n - a simple string that is matched literally from the input\n  string.\n\n\nRegEx match\n - regular expression match (based on python \nre\n module).\n\n\n\n\n\n\n\n\nnon-terminal match rules\n - create a \nNon-terminal nodes\n:\n\n\n\n\nSequence\n - succeeds if all parsing expressions matches at current\n  location in the defined order.  Matched input is consumed.\n\n\nOrdered choice\n - succeeds if any of the given expressions matches at the\n  current location. The match is tried in the order defined. Matched input is\n  consumed.\n\n\nZero or more\n - given expression is matched until match is successful.\n  Always succeeds. Matched input is consumed.\n\n\nOne or more\n - given expressions is matched until match is successful.\n  Succeeds if at least one match is done. Matched input is consumed.\n\n\nOptional\n - matches given expression but will not fail if match can't be\n  done. Matched input is consumed.\n\n\nAnd predicate\n - succeeds if given expression matches at current location\n  but does not consume any input.\n\n\nNot predicate\n - succeeds if given expression \ndoes not\n matches at\n  current location but does not consume any input.\n\n\n\n\n\n\n\n\nPEG grammars in Arpeggio may be written twofold:\n\n\n\n\nUsing Python statements and expressions.\n\n\nUsing textual PEG syntax (currently there are two variants, see below).\n\n\n\n\nGrammars written in Python\n\n\nCanonical form of grammar specification uses Python statements and expressions.\n\n\nHere is an example of arpeggio grammar for simple calculator:\n\n\ndef number():     return _(r'\\d*\\.\\d*|\\d+')\ndef factor():     return Optional([\"+\",\"-\"]), [number,\n                          (\"(\", expression, \")\")]\ndef term():       return factor, ZeroOrMore([\"*\",\"/\"], factor)\ndef expression(): return term, ZeroOrMore([\"+\", \"-\"], term)\ndef calc():       return OneOrMore(expression), EOF\n\n\n\nEach rule is given in the form of Python function. Python function returns data\nstructure that maps to PEG expressions.\n\n\n\n\nSequence\n is represented as Python tuple.\n\n\nOrdered choice\n is represented as Python list where each element is one\n  alternative.\n\n\nOne or more\n is represented as an instance of \nOneOrMore\n class.\n  The parameters are treated as a containing sequence.\n\n\nZero or more\n is represented as an instance of \nZeroOrMore\n class.\n  The parameters are treated as a containing sequence.\n\n\nOptional\n is represented as an instance of \nOptional\n class.\n\n\nAnd predicate\n is represented as an instance of \nAnd\n class.\n\n\nNot predicate\n is represented as an instance of \nNot\n class.\n\n\nLiteral string match\n is represented as string or regular expression given\n  as an instance of \nRegExMatch\n class.\n\n\nEnd of string/file\n is recognized by the \nEOF\n special rule.\n\n\n\n\nFor example, the \ncalc\n language consists of one or more \nexpression\n and\nend of file.\n\n\nfactor\n rule consists of optional \n+\n or \n-\n char matched in that order\n(they are given in Python list thus ordered choice) followed by the ordered\nchoice of \nnumber\n rule and a sequence of \nexpression\n rule in brackets.\nThis rule will match an optional sign (\n+\n or \n-\n tried in that order) after\nwhich follows a \nnumber\n or an \nexpression\n in brackets (tried in that\norder).\n\n\nFrom this description Arpeggio builds \nthe parser model\n. Parser model is a\ngraph of parser expressions (see \nGrammar\nvisualization\n).  Each node of the graph is\nan instance of some of the classes described above which inherits\n\nParserExpression\n.\n\n\nParser model construction is done during parser instantiation.  For example, to\ninstantiate \ncalc\n parser you do the following:\n\n\nparser = ParserPython(calc)\n\n\n\n\nWhere \ncalc\n is the function defining the root rule of your grammar. There is no\ncode generation. Parser works as an interpreter for your grammar. The grammar is\nused to configure Arpeggio parser to recognize your language (in this case the\n\ncalc\n language). In other words, Arpeggio interprets the parser model (your\ngrammar).\n\n\nAfter parser construction your can call \nparser.parse\n to parse your input\ntext.\n\n\ninput_expr = \"-(4-1)*5+(2+4.67)+5.89/(.2+7)\"\nparse_tree = parser.parse(input_expr)\n\n\n\n\nArpeggio will start from the root node and traverse \nthe parser model graph\n\nconsuming all matched input.  When all root node branches are traversed the\nparsing is done and \nthe parse tree\n is returned.\n\n\nYou can navigate and analyze parse tree or transform it using visitor pattern to\nsome more usable form (see \nSemantic analysis - Visitors\n)\n\n\nGrammars written in PEG notations\n\n\nGrammars can also be specified using PEG notation. There are actually two of\nthem at the moment and both notations are implemented using canonical Python\nbased grammars (see modules\n\narpeggio.peg\n\nand\n\narpeggio.cleanpeg\n).\n\n\nThere are no significant differences between those two syntax. The first one use\nmore traditional approach using \n<-\n for rule assignment, \n//\n for line comments\nand \n;\n for the rule terminator.  The second syntax (from \narpeggio.cleanpeg\n)\nuses \n=\n for assignment, does not use rule terminator and use \n#\n for line\ncomments. Which one you choose is totally up to you. If your don't like any of\nthese syntaxes you can make your own (look at \narpeggio.peg\n and\n\narpeggio.cleanpeg\n modules as an examples).\n\n\nAn example of the \ncalc\n grammar given in PEG syntax (\narpeggio.cleanpeg\n):\n\n\nnumber = r'\\d*\\.\\d*|\\d+'\nfactor = (\"+\" / \"-\")? (number / \"(\" expression \")\")\nterm = factor (( \"*\" / \"/\") factor)*\nexpression = term ((\"+\" / \"-\") term)*\ncalc = expression+ EOF\n\n\n\n\nEach grammar rule is given as an assignment where the lhs is the rule name (e.g.\n\nnumber\n) and the rhs is a PEG expression.\n\n\n\n\nLiteral string matches\n are given as strings (e.g. \n\"+\"\n).\n\n\nRegex matches\n are given as strings with prefix \nr\n (e.g.\n  \nr'\\d*\\.\\d*|\\d+'\n).\n\n\nSequence\n is a space separated list of expressions (e.g. \nexpression+\n  EOF\n is a sequence of two expressions).\n\n\nOrdered choice\n is a list of expression separated with \n/\n (e.g. \n\"+\" /\n  \"-\"\n).\n\n\nZero or more\n expression is specified by \n*\n operator (e.g. \n(( \"*\" /\n  \"/\" ) factor)*\n).\n\n\nOne of more\n is specified by \n+\n operator (e.g. \nexpression+\n).\n\n\n\n\nAnd\n and \nNot\n predicates are also supported.\n\n\n\n\nAnd predicate\n is specified by \n&\n operator (e.g. \n&expression\n - not\n  used in the grammar above).\n\n\nNot predicate\n is specified by \n!\n operator (e.g. \n!expression\n - not\n  used in the grammar above).\n\n\n\n\nIn the rhs a rule reference is a name of another rule. Parser will try to match\nanother rule at that location.\n\n\nSpecial rule \nEOF\n will match end of input string.\n\n\nCreating a parser using PEG syntax is done by the class \nParserPEG\n from the\n\narpeggio.peg\n or \narpeggio.cleanpeg\n modules.\n\n\nfrom arpeggio.cleanpeg import ParserPEG\nparser = ParserPEG(calc_grammar, \"calc\")\n\n\n\n\nWhere \ncalc_grammar\n is a string with the grammar given above and the\n\n\"calc\"\n is the name of the root rule of the grammar.\n\n\nAfter this you get the same parser as with the \nParserPython\n. There is no\ndifference at all so you can parse the same language.\n\n\ninput_expr = \"-(4-1)*5+(2+4.67)+5.89/(.2+7)\"\nparse_tree = parser.parse(input_expr)\n\n\n\n\n\n\nNote\n\n\nJust remember that using textual PEG syntax imposes a slight overhead since\nthe grammar must be parsed and the parser for your language must be built by\nsemantic analysis of grammar parse tree.  If you plan to instantiate your\nparser once and than use it many times this shall not have that much of\nperformance hit but if your workflow introduce instantiating parser each time\nyour parse some input than consider defining your grammar using Python as it\nwill start faster.  Nevertheless, the parsing performance will be the same in\nboth approach since the same code for parsing is used.",
            "title": "Grammars"
        },
        {
            "location": "/grammars/#grammars",
            "text": "With grammar you teach Arpeggio how to parse your inputs.   Arpeggio is based on  PEG grammars .\nPEG is a type of formal grammar that is given as a set of rules for recognizing\nstrings of the language.  In a way it is similar to context-free grammars with a\nvery important distinction that PEG are always unambiguous. This is achieved by\nmaking choice operator ordered. In PEGs a first choice from left to right that\nmatches will be used.   Note  More information on PEGs can be found on  this page .   PEG grammar is a set of PEG rules. PEG rules consists of parsing expressions and\ncan reference (call) each other.  Example grammar in PEG notation:  first = 'foo' second+ EOF\nsecond = 'bar' / 'baz'  In this example  first  is the root rule. This rule will match a literal\nstring  foo  followed by one or more  second  rule (this is a rule\nreference) followed by end of input ( EOF ).   second  rule is ordered\nchoice and will match either  bar  or  baz  in that order.  During parsing each successfully matched rule will create a parse tree node.  At\nthe end of parsing a complete  parse tree  of the input will be\nreturned.  .  In Arpeggio each PEG rule consists of atomic parsing expression which can be:    terminal match rules  - create a  Terminal nodes :   String match  - a simple string that is matched literally from the input\n  string.  RegEx match  - regular expression match (based on python  re  module).     non-terminal match rules  - create a  Non-terminal nodes :   Sequence  - succeeds if all parsing expressions matches at current\n  location in the defined order.  Matched input is consumed.  Ordered choice  - succeeds if any of the given expressions matches at the\n  current location. The match is tried in the order defined. Matched input is\n  consumed.  Zero or more  - given expression is matched until match is successful.\n  Always succeeds. Matched input is consumed.  One or more  - given expressions is matched until match is successful.\n  Succeeds if at least one match is done. Matched input is consumed.  Optional  - matches given expression but will not fail if match can't be\n  done. Matched input is consumed.  And predicate  - succeeds if given expression matches at current location\n  but does not consume any input.  Not predicate  - succeeds if given expression  does not  matches at\n  current location but does not consume any input.     PEG grammars in Arpeggio may be written twofold:   Using Python statements and expressions.  Using textual PEG syntax (currently there are two variants, see below).",
            "title": "Grammars"
        },
        {
            "location": "/grammars/#grammars-written-in-python",
            "text": "Canonical form of grammar specification uses Python statements and expressions.  Here is an example of arpeggio grammar for simple calculator:  def number():     return _(r'\\d*\\.\\d*|\\d+')\ndef factor():     return Optional([\"+\",\"-\"]), [number,\n                          (\"(\", expression, \")\")]\ndef term():       return factor, ZeroOrMore([\"*\",\"/\"], factor)\ndef expression(): return term, ZeroOrMore([\"+\", \"-\"], term)\ndef calc():       return OneOrMore(expression), EOF  Each rule is given in the form of Python function. Python function returns data\nstructure that maps to PEG expressions.   Sequence  is represented as Python tuple.  Ordered choice  is represented as Python list where each element is one\n  alternative.  One or more  is represented as an instance of  OneOrMore  class.\n  The parameters are treated as a containing sequence.  Zero or more  is represented as an instance of  ZeroOrMore  class.\n  The parameters are treated as a containing sequence.  Optional  is represented as an instance of  Optional  class.  And predicate  is represented as an instance of  And  class.  Not predicate  is represented as an instance of  Not  class.  Literal string match  is represented as string or regular expression given\n  as an instance of  RegExMatch  class.  End of string/file  is recognized by the  EOF  special rule.   For example, the  calc  language consists of one or more  expression  and\nend of file.  factor  rule consists of optional  +  or  -  char matched in that order\n(they are given in Python list thus ordered choice) followed by the ordered\nchoice of  number  rule and a sequence of  expression  rule in brackets.\nThis rule will match an optional sign ( +  or  -  tried in that order) after\nwhich follows a  number  or an  expression  in brackets (tried in that\norder).  From this description Arpeggio builds  the parser model . Parser model is a\ngraph of parser expressions (see  Grammar\nvisualization ).  Each node of the graph is\nan instance of some of the classes described above which inherits ParserExpression .  Parser model construction is done during parser instantiation.  For example, to\ninstantiate  calc  parser you do the following:  parser = ParserPython(calc)  Where  calc  is the function defining the root rule of your grammar. There is no\ncode generation. Parser works as an interpreter for your grammar. The grammar is\nused to configure Arpeggio parser to recognize your language (in this case the calc  language). In other words, Arpeggio interprets the parser model (your\ngrammar).  After parser construction your can call  parser.parse  to parse your input\ntext.  input_expr = \"-(4-1)*5+(2+4.67)+5.89/(.2+7)\"\nparse_tree = parser.parse(input_expr)  Arpeggio will start from the root node and traverse  the parser model graph \nconsuming all matched input.  When all root node branches are traversed the\nparsing is done and  the parse tree  is returned.  You can navigate and analyze parse tree or transform it using visitor pattern to\nsome more usable form (see  Semantic analysis - Visitors )",
            "title": "Grammars written in Python"
        },
        {
            "location": "/grammars/#grammars-written-in-peg-notations",
            "text": "Grammars can also be specified using PEG notation. There are actually two of\nthem at the moment and both notations are implemented using canonical Python\nbased grammars (see modules arpeggio.peg \nand arpeggio.cleanpeg ).  There are no significant differences between those two syntax. The first one use\nmore traditional approach using  <-  for rule assignment,  //  for line comments\nand  ;  for the rule terminator.  The second syntax (from  arpeggio.cleanpeg )\nuses  =  for assignment, does not use rule terminator and use  #  for line\ncomments. Which one you choose is totally up to you. If your don't like any of\nthese syntaxes you can make your own (look at  arpeggio.peg  and arpeggio.cleanpeg  modules as an examples).  An example of the  calc  grammar given in PEG syntax ( arpeggio.cleanpeg ):  number = r'\\d*\\.\\d*|\\d+'\nfactor = (\"+\" / \"-\")? (number / \"(\" expression \")\")\nterm = factor (( \"*\" / \"/\") factor)*\nexpression = term ((\"+\" / \"-\") term)*\ncalc = expression+ EOF  Each grammar rule is given as an assignment where the lhs is the rule name (e.g. number ) and the rhs is a PEG expression.   Literal string matches  are given as strings (e.g.  \"+\" ).  Regex matches  are given as strings with prefix  r  (e.g.\n   r'\\d*\\.\\d*|\\d+' ).  Sequence  is a space separated list of expressions (e.g.  expression+\n  EOF  is a sequence of two expressions).  Ordered choice  is a list of expression separated with  /  (e.g.  \"+\" /\n  \"-\" ).  Zero or more  expression is specified by  *  operator (e.g.  (( \"*\" /\n  \"/\" ) factor)* ).  One of more  is specified by  +  operator (e.g.  expression+ ).   And  and  Not  predicates are also supported.   And predicate  is specified by  &  operator (e.g.  &expression  - not\n  used in the grammar above).  Not predicate  is specified by  !  operator (e.g.  !expression  - not\n  used in the grammar above).   In the rhs a rule reference is a name of another rule. Parser will try to match\nanother rule at that location.  Special rule  EOF  will match end of input string.  Creating a parser using PEG syntax is done by the class  ParserPEG  from the arpeggio.peg  or  arpeggio.cleanpeg  modules.  from arpeggio.cleanpeg import ParserPEG\nparser = ParserPEG(calc_grammar, \"calc\")  Where  calc_grammar  is a string with the grammar given above and the \"calc\"  is the name of the root rule of the grammar.  After this you get the same parser as with the  ParserPython . There is no\ndifference at all so you can parse the same language.  input_expr = \"-(4-1)*5+(2+4.67)+5.89/(.2+7)\"\nparse_tree = parser.parse(input_expr)   Note  Just remember that using textual PEG syntax imposes a slight overhead since\nthe grammar must be parsed and the parser for your language must be built by\nsemantic analysis of grammar parse tree.  If you plan to instantiate your\nparser once and than use it many times this shall not have that much of\nperformance hit but if your workflow introduce instantiating parser each time\nyour parse some input than consider defining your grammar using Python as it\nwill start faster.  Nevertheless, the parsing performance will be the same in\nboth approach since the same code for parsing is used.",
            "title": "Grammars written in PEG notations"
        },
        {
            "location": "/parse_trees/",
            "text": "Parse trees\n\n\nParse tree is a first structure you get from a successful parse.\n\n\n\n\nParse tree or concrete syntax tree is a tree structure built from the input\nstring during parsing.  It represent the structure of the input string. Each\nnode in the parse tree is either a \nterminal\n or\n\nnon-terminal\n. Terminals are the leafs of the tree while\nthe inner nodes are non-terminals.\n\n\nHere is an example parse tree for the \ncalc\n grammar and the expression\n\n-(4-1)*5+(2+4.67)+5.89/(.2+7)\n:\n\n\n\n\nEach non-leaf node is non-terminal. The name in this nodes are the names of the\ngrammar PEG rules that created them.\n\n\nThe leaf nodes are terminals and they are matched by the \nstring match\n or \nregex\nmatch\n rules.\n\n\nIn the square brackets is the location in the input stream where the\nterminal/non-terminal is recognized.\n\n\nEach parse tree node has the following attributes:\n\n\n\n\nrule\n - the parsing expression that created this node.\n\n\nrule_name\n - the name of the rule if it was the root rule or empty string\n  otherwise.\n\n\nposition\n - the position in the input stream where this node was\n  recognized.\n\n\n\n\nTerminal nodes\n\n\nTerminals in Arpeggio are created by the specializations of the parsing\nexpression \nMatch\n class.  There are two specialization of \nMatch\n class:\n\n\n\n\nStrMatch\n if the literal string is matched from the input or\n\n\nRegExMatch\n if a regular expression is used to match input.\n\n\n\n\nTo get the matched string from the terminal object just convert it to string\n(e.g. \nstr(t)\n where \nt\n is of \nTerminal\n type).\n\n\nNon-terminal nodes\n\n\nNon-terminal nodes are non-leaf nodes of the parse tree. They are created by PEG\ngrammar rules.  Children of non-terminals can be other non-terminals or\nterminals.\n\n\nFor example, nodes with the labels \nexpression\n, \nfactor\n and \nterm\n from\nthe above parse tree are non-terminal nodes created by the rules with the same\nnames.\n\n\nNonTerminal\n inherits from \nlist\n. The elements of \nNonTerminal\n are its\nchildren nodes.  So, you can use index access:\n\n\nchild = pt_node[2]\n\n\n\n\nOr iteration:\n\n\nfor child in pt_node:\n  ...\n\n\n\n\nAdditionally, you can access children by the child rule name:\n\n\nFor example:\n\n\n# Grammar\ndef foo(): return \"a\", bar, \"b\", baz, \"c\", ZeroOrMore(bar)\ndef bar(): return \"bar\"\ndef baz(): return \"baz\"\n\n# Parsing\nparser = ParserPython(foo)\nresult = parser.parse(\"a bar b baz c bar bar bar\")\n\n# Accessing parse tree nodes. All asserts will pass.\n# Index access\nassert result[1].rule_name  == 'bar'\n# Access by rule name\nassert result.bar.rule_name == 'bar'\n\n# There are 8 children nodes of the root 'result' node.\n# Each child is a terminal in this case.\nassert len(result) == 8\n\n# There is 4 bar matched from result (at the beginning and from ZeroOrMore)\n# Dot access collect all NTs from the given path\nassert len(result.bar) == 4\n# You could call dot access recursively, e.g. result.bar.baz if the\n# rule bar called baz. In that case all bars would be collected from\n# the root and for each bar all baz will be collected.\n\n# Verify position\n# First 'bar' is at position 2 and second is at position 14\nassert result.bar[0].position == 2\nassert result.bar[1].position == 14\n\n\n\n\n\nParse tree reduction\n\n\nParser can be configured to create a reduced parse tree. More information can be\nfound \nhere\n.",
            "title": "Parse tree"
        },
        {
            "location": "/parse_trees/#parse-trees",
            "text": "Parse tree is a first structure you get from a successful parse.   Parse tree or concrete syntax tree is a tree structure built from the input\nstring during parsing.  It represent the structure of the input string. Each\nnode in the parse tree is either a  terminal  or non-terminal . Terminals are the leafs of the tree while\nthe inner nodes are non-terminals.  Here is an example parse tree for the  calc  grammar and the expression -(4-1)*5+(2+4.67)+5.89/(.2+7) :   Each non-leaf node is non-terminal. The name in this nodes are the names of the\ngrammar PEG rules that created them.  The leaf nodes are terminals and they are matched by the  string match  or  regex\nmatch  rules.  In the square brackets is the location in the input stream where the\nterminal/non-terminal is recognized.  Each parse tree node has the following attributes:   rule  - the parsing expression that created this node.  rule_name  - the name of the rule if it was the root rule or empty string\n  otherwise.  position  - the position in the input stream where this node was\n  recognized.",
            "title": "Parse trees"
        },
        {
            "location": "/parse_trees/#terminal-nodes",
            "text": "Terminals in Arpeggio are created by the specializations of the parsing\nexpression  Match  class.  There are two specialization of  Match  class:   StrMatch  if the literal string is matched from the input or  RegExMatch  if a regular expression is used to match input.   To get the matched string from the terminal object just convert it to string\n(e.g.  str(t)  where  t  is of  Terminal  type).",
            "title": "Terminal nodes"
        },
        {
            "location": "/parse_trees/#non-terminal-nodes",
            "text": "Non-terminal nodes are non-leaf nodes of the parse tree. They are created by PEG\ngrammar rules.  Children of non-terminals can be other non-terminals or\nterminals.  For example, nodes with the labels  expression ,  factor  and  term  from\nthe above parse tree are non-terminal nodes created by the rules with the same\nnames.  NonTerminal  inherits from  list . The elements of  NonTerminal  are its\nchildren nodes.  So, you can use index access:  child = pt_node[2]  Or iteration:  for child in pt_node:\n  ...  Additionally, you can access children by the child rule name:  For example:  # Grammar\ndef foo(): return \"a\", bar, \"b\", baz, \"c\", ZeroOrMore(bar)\ndef bar(): return \"bar\"\ndef baz(): return \"baz\"\n\n# Parsing\nparser = ParserPython(foo)\nresult = parser.parse(\"a bar b baz c bar bar bar\")\n\n# Accessing parse tree nodes. All asserts will pass.\n# Index access\nassert result[1].rule_name  == 'bar'\n# Access by rule name\nassert result.bar.rule_name == 'bar'\n\n# There are 8 children nodes of the root 'result' node.\n# Each child is a terminal in this case.\nassert len(result) == 8\n\n# There is 4 bar matched from result (at the beginning and from ZeroOrMore)\n# Dot access collect all NTs from the given path\nassert len(result.bar) == 4\n# You could call dot access recursively, e.g. result.bar.baz if the\n# rule bar called baz. In that case all bars would be collected from\n# the root and for each bar all baz will be collected.\n\n# Verify position\n# First 'bar' is at position 2 and second is at position 14\nassert result.bar[0].position == 2\nassert result.bar[1].position == 14",
            "title": "Non-terminal nodes"
        },
        {
            "location": "/parse_trees/#parse-tree-reduction",
            "text": "Parser can be configured to create a reduced parse tree. More information can be\nfound  here .",
            "title": "Parse tree reduction"
        },
        {
            "location": "/handling_errors/",
            "text": "Handling syntax errors in the input\n\n\nThis section explains how to handle parsing errors.\n\n\n\n\nIf your grammar is correct but you get input string with syntax error parser\nwill raise \nNoMatch\n exception with the information where in the input stream\nerror has occurred and what the parser expect to see at that location.\n\n\nBy default, if \nNoMatch\n is not caught you will get detailed explanation of\nthe error on the console.  The exact location will be reported, the context\n(part of the input where the error occurred) and the first rule that was tried\nat that location.\n\n\nExample:\n\n\nparser = ParserPython(calc)\n# 'r' in the following expression can't be recognized by\n# calc grammar\ninput_expr = \"23+4/r-89\"\nparse_tree = parser.parse(input_expr)\n\n\n\n\nAs there is an error in the \ninput_expr\n string (\nr\n is not expected) the \nfollowing traceback will be printed:\n\n\nTraceback (most recent call last):\n  ...\narpeggio.NoMatch: Expected '+' at position (1, 6) => '23+4/*r-89'.\n\n\n\nThe place in the input stream is marked by \n*\n and the position in (row, col) is\ngiven (\n(1, 6)\n).\n\n\nIf you wish to handle syntax errors gracefully you can catch \nNoMatch\n in your\ncode and inspect its attributes.\n\n\ntry:\n  parser = ParserPython(calc)\n  input_expr = \"23+4/r-89\"\n  parse_tree = parser.parse(input_expr)\nexcept NoMatch as e:\n  # Do something with e\n\n\n\n\nNoMatch\n class has the following attributes:\n\n\n\n\nrule\n - A \nParsingExpression\n rule that is the source of the exception.\n\n\nposition\n - A position in the input stream where exception occurred.\n\n\nparser\n - A \nParser\n instance used for parsing.\n\n\nexp_str\n -  What is expected? If not given it is deduced from the rule. Currently\n  this is used by \ntextX\n for nicer\n  error reporting.\n\n\n\n\nThe \nposition\n is given as the offset from the beginning of the input string.\nTo convert it to row and column use \npos_to_linecol\n method of the parser.\n\n\ntry:\n  parser = ParserPython(calc)\n  input_expr = \"23+4/r-89\"\n  parse_tree = parser.parse(input_expr)\nexcept NoMatch as e:\n  line, col = e.parser.pos_to_linecol(e.position)\n  ...\n\n\n\n\nArpeggio is a backtracking parser, which means that it will go back and try\nanother alternatives when the match does not succeeds but it will nevertheless\nreport the furthest place in the input where it failed.  Currently Arpeggio will\nreport the first rule it tried at that location. Future versions could keep the\nlist of all rules that was tried at reported location.",
            "title": "Handling errors"
        },
        {
            "location": "/handling_errors/#handling-syntax-errors-in-the-input",
            "text": "This section explains how to handle parsing errors.   If your grammar is correct but you get input string with syntax error parser\nwill raise  NoMatch  exception with the information where in the input stream\nerror has occurred and what the parser expect to see at that location.  By default, if  NoMatch  is not caught you will get detailed explanation of\nthe error on the console.  The exact location will be reported, the context\n(part of the input where the error occurred) and the first rule that was tried\nat that location.  Example:  parser = ParserPython(calc)\n# 'r' in the following expression can't be recognized by\n# calc grammar\ninput_expr = \"23+4/r-89\"\nparse_tree = parser.parse(input_expr)  As there is an error in the  input_expr  string ( r  is not expected) the \nfollowing traceback will be printed:  Traceback (most recent call last):\n  ...\narpeggio.NoMatch: Expected '+' at position (1, 6) => '23+4/*r-89'.  The place in the input stream is marked by  *  and the position in (row, col) is\ngiven ( (1, 6) ).  If you wish to handle syntax errors gracefully you can catch  NoMatch  in your\ncode and inspect its attributes.  try:\n  parser = ParserPython(calc)\n  input_expr = \"23+4/r-89\"\n  parse_tree = parser.parse(input_expr)\nexcept NoMatch as e:\n  # Do something with e  NoMatch  class has the following attributes:   rule  - A  ParsingExpression  rule that is the source of the exception.  position  - A position in the input stream where exception occurred.  parser  - A  Parser  instance used for parsing.  exp_str  -  What is expected? If not given it is deduced from the rule. Currently\n  this is used by  textX  for nicer\n  error reporting.   The  position  is given as the offset from the beginning of the input string.\nTo convert it to row and column use  pos_to_linecol  method of the parser.  try:\n  parser = ParserPython(calc)\n  input_expr = \"23+4/r-89\"\n  parse_tree = parser.parse(input_expr)\nexcept NoMatch as e:\n  line, col = e.parser.pos_to_linecol(e.position)\n  ...  Arpeggio is a backtracking parser, which means that it will go back and try\nanother alternatives when the match does not succeeds but it will nevertheless\nreport the furthest place in the input where it failed.  Currently Arpeggio will\nreport the first rule it tried at that location. Future versions could keep the\nlist of all rules that was tried at reported location.",
            "title": "Handling syntax errors in the input"
        },
        {
            "location": "/debugging/",
            "text": "Debugging\n\n\nWhen the stuff goes wrong you will want to debug your parser.\n\n\n\n\nParser debug mode\n\n\nDuring grammar design you can make syntax and semantic errors. Arpeggio will\nreport any syntax error with all the necessary information whether you are\nbuilding parser from python expressions or from a textual PEG notation.\n\n\nFor semantic error you have a debugging mode of operation which is entered by\nsetting \ndebug\n parameter to \nTrue\n in the parser construction call. \n\n\nparser = ParserPython(calc, debug=True)\n\n\n\n\nWhen Arpeggio runs in debug mode it will print a detailed information of what it\nis doing.\n\n\n>> Entering rule calc=Sequence at position 0 => *-(4-1)*5+(\n  >> Entering rule OneOrMore in calc at position 0 => *-(4-1)*5+(\n      >> Entering rule expression=Sequence in calc at position 0 => *-(4-1)*5+(\n        >> Entering rule term=Sequence in expression at position 0 => *-(4-1)*5+(\n            >> Entering rule factor=Sequence in term at position 0 => *-(4-1)*5+(\n              >> Entering rule Optional in factor at position 0 => *-(4-1)*5+(\n                  >> Entering rule OrderedChoice in factor at position 0 => *-(4-1)*5+(\n                    >> Match rule StrMatch(+) in factor at position 0 => *-(4-1)*5+(\n                        -- No match '+' at 0 => '*-*(4-1)*5+('\n                    >> Match rule StrMatch(-) in factor at position 0 => *-(4-1)*5+(\n                        ++ Match '-' at 0 => '*-*(4-1)*5+('\n                  << Leaving rule OrderedChoice\n              << Leaving rule Optional\n              >> Entering rule OrderedChoice in factor at position 1 => -*(4-1)*5+(2\n\n\n\nGrammar visualization\n\n\nFurthermore, while running in debug mode, a \ndot\n file (a graph description file\nformat from \nGraphViz software\npackage\n) representing \nthe parser\nmodel\n ill be created if the parser model is constructed without errors. \n\n\nThis \ndot\n file can be rendered as image using one of available dot viewer\nsoftware or transformed to an image using \ndot\n tool\n\nGraphViz\n software.\n\n\n$ dot -Tpng -O calc_parser_model.dot\n\n\n\n\nAfter this command you will get \ncalc_parser_model.dot.png\n file which can be\nopened in any \npng\n image viewer. This is how it looks like:\n\n\n\n\nEach node in this graph is a parsing expression.  Nodes are labeled by the type\nname of the parsing expression.  If node represents the rule from the grammar\nthe label is of the form \n<rule_name>=<PEG type>\n where \nrule_name\n it the\nname of the grammar rule.  The edges connect children expressions. The labels on\nthe edges represent the order in which the graph will be traversed during\nparsing.\n\n\nFurthermore, if you parse some input while the parser is in debug mode, the\nparse tree \ndot\n file will be generated also.\n\n\nparse_tree = parser.parse(\"-(4-1)*5+(2+4.67)+5.89/(.2+7)\")\n\n\n\n\nThis \ndot\n file can also be converted to \npng\n with the command:\n\n\n$ dot -Tpng -O calc_parse_tree.dot\n\n\n\n\nWhich produces \npng\n image given bellow.\n\n\n\n\nYou can also explicitly render your parser model or parse tree to \ndot\n file\neven if the parser is not in the debug mode.\n\n\nFor parser model this is achieved with the following Python code:\n\n\nfrom arpeggio.export import PMDOTExporter\nPMDOTExporter().exportFile(parser.parser_model,\n                            \"my_parser_model.dot\")\n\n\n\n\nFor parse tree it is achieved with:\n\n\nfrom arpeggio.export import PTDOTExporter\nPTDOTExporter().exportFile(parse_tree,\n                           \"my_parse_tree.dot\")\n\n\n\n\nTo get e.g. \npng\n images from \ndot\n files do as usuall:\n\n\n$ dot -Tpng -O *dot\n\n\n\n\n\n\n\nNote\n\n\nAll tree images in this docs are rendered using Arpeggio's visualization and\n\ndot\n tool from the \nGraphViz\n software.",
            "title": "Debugging"
        },
        {
            "location": "/debugging/#debugging",
            "text": "When the stuff goes wrong you will want to debug your parser.",
            "title": "Debugging"
        },
        {
            "location": "/debugging/#parser-debug-mode",
            "text": "During grammar design you can make syntax and semantic errors. Arpeggio will\nreport any syntax error with all the necessary information whether you are\nbuilding parser from python expressions or from a textual PEG notation.  For semantic error you have a debugging mode of operation which is entered by\nsetting  debug  parameter to  True  in the parser construction call.   parser = ParserPython(calc, debug=True)  When Arpeggio runs in debug mode it will print a detailed information of what it\nis doing.  >> Entering rule calc=Sequence at position 0 => *-(4-1)*5+(\n  >> Entering rule OneOrMore in calc at position 0 => *-(4-1)*5+(\n      >> Entering rule expression=Sequence in calc at position 0 => *-(4-1)*5+(\n        >> Entering rule term=Sequence in expression at position 0 => *-(4-1)*5+(\n            >> Entering rule factor=Sequence in term at position 0 => *-(4-1)*5+(\n              >> Entering rule Optional in factor at position 0 => *-(4-1)*5+(\n                  >> Entering rule OrderedChoice in factor at position 0 => *-(4-1)*5+(\n                    >> Match rule StrMatch(+) in factor at position 0 => *-(4-1)*5+(\n                        -- No match '+' at 0 => '*-*(4-1)*5+('\n                    >> Match rule StrMatch(-) in factor at position 0 => *-(4-1)*5+(\n                        ++ Match '-' at 0 => '*-*(4-1)*5+('\n                  << Leaving rule OrderedChoice\n              << Leaving rule Optional\n              >> Entering rule OrderedChoice in factor at position 1 => -*(4-1)*5+(2",
            "title": "Parser debug mode"
        },
        {
            "location": "/debugging/#grammar-visualization",
            "text": "Furthermore, while running in debug mode, a  dot  file (a graph description file\nformat from  GraphViz software\npackage ) representing  the parser\nmodel  ill be created if the parser model is constructed without errors.   This  dot  file can be rendered as image using one of available dot viewer\nsoftware or transformed to an image using  dot  tool GraphViz  software.  $ dot -Tpng -O calc_parser_model.dot  After this command you will get  calc_parser_model.dot.png  file which can be\nopened in any  png  image viewer. This is how it looks like:   Each node in this graph is a parsing expression.  Nodes are labeled by the type\nname of the parsing expression.  If node represents the rule from the grammar\nthe label is of the form  <rule_name>=<PEG type>  where  rule_name  it the\nname of the grammar rule.  The edges connect children expressions. The labels on\nthe edges represent the order in which the graph will be traversed during\nparsing.  Furthermore, if you parse some input while the parser is in debug mode, the\nparse tree  dot  file will be generated also.  parse_tree = parser.parse(\"-(4-1)*5+(2+4.67)+5.89/(.2+7)\")  This  dot  file can also be converted to  png  with the command:  $ dot -Tpng -O calc_parse_tree.dot  Which produces  png  image given bellow.   You can also explicitly render your parser model or parse tree to  dot  file\neven if the parser is not in the debug mode.  For parser model this is achieved with the following Python code:  from arpeggio.export import PMDOTExporter\nPMDOTExporter().exportFile(parser.parser_model,\n                            \"my_parser_model.dot\")  For parse tree it is achieved with:  from arpeggio.export import PTDOTExporter\nPTDOTExporter().exportFile(parse_tree,\n                           \"my_parse_tree.dot\")  To get e.g.  png  images from  dot  files do as usuall:  $ dot -Tpng -O *dot   Note  All tree images in this docs are rendered using Arpeggio's visualization and dot  tool from the  GraphViz  software.",
            "title": "Grammar visualization"
        },
        {
            "location": "/configuration/",
            "text": "Parser configuration\n\n\nThis section describes how to alter parser default behaviour.\n\n\n\n\nThere are some aspect of parsing that can be configured using parser and/or\n\nParsingExpression\n parameters.  Arpeggio has some sane default behaviour but\ngives the user possibility to alter it.\n\n\nThis section describes various parser parameters.\n\n\nCase insensitive parsing\n\n\nBy default Arpeggio is case sensitive. If you wish to do case insensitive\nparsing set parser parameter \nignore_case\n to \nTrue\n.\n\n\nparser = ParserPython(calc, ignore_case=True)\n\n\n\n\nWhite-space handling\n\n\nArpeggio by default skips white-spaces. You can change this behaviour with the\nparameter \nskipws\n given to parser constructor.\n\n\nparser = ParserPython(calc, skipws=False)\n\n\n\n\nYou can also change what is considered a whitespace by Arpeggio using the \nws\n\nparameter. It is a plain string that consists of white-space characters. By\ndefault it is set to \n\"\\t\\n\\r \"\n.\n\n\nFor example, to prevent a newline to be treated as whitespace you could write:\n\n\nparser = ParserPython(calc, ws='\\t\\r ')\n\n\n\n\n\n\nNote\n\n\nThese parameters can be used on the \nSequence\n level so one could write\ngrammar like this:\n\n\ndef grammar():     return Sequence(\"one\", \"two\", \"three\",\n                                   skipws=False), \"four\"\nparser = ParserPython(grammar)\n\n\n\n\n\nKeyword handling\n\n\nBy setting a \nautokwd\n parameter to \nTrue\n a word boundary match for\nkeyword-like matches will be performed.\n\n\nThis parameter is disabled by default.\n\n\n  def grammar():     return \"one\", \"two\", \"three\"\n\n  parser = ParserPython(grammar, autokwd=True)\n\n  # If autokwd is enabled this should parse without error.\n  parser.parse(\"one two three\")\n\n  # But this will not parse as the match is done using word boundaries\n  # so this is considered a one word.\n  parser.parse(\"onetwothree\")\n\n\n\nComment handling\n\n\nSupport for comments in your language can be specified as another set of grammar\nrules.  See \nsimple.py example\n.\n\n\nParser is constructed using two parameters.\n\n\nparser = ParserPython(simpleLanguage, comment)\n\n\n\n\nFirst parameter is the root rule of main parse model while the second is a rule\nfor comments.\n\n\nDuring parsing comment parse trees are kept in the separate list thus comments\nwill not show in the main parse tree.\n\n\nParse tree reduction\n\n\nNon-terminals are by default created for each rule. Sometimes it can result in\ntrees of great depth.  You can alter this behaviour setting \nreduce_tree\n\nparameter to \nTrue\n.\n\n\nparser = ParserPython(calc, reduce_tree=True)\n\n\n\n\nIn this configuration non-terminals with single child will be removed from the\nparse tree.\n\n\nFor example, \ncalc\n parse tree above will look like this:\n\n\n\n\nNotice the removal of each non-terminal with single child.\n\n\n\n\nWarning\n\n\nBe aware that \nsemantic analysis\n operates on nodes of\nfinished parse tree. Therefore, it you use \ntree\nreduction\n visitor methods will not\nget called for the removed nodes.\n\n\n\n\nNewline termination for Repetitions\n\n\nBy default \nRepetition\n parsing expressions (i.e. \nZeroOrMore\n and\n\nOneOrMore\n) will obey \nskipws\n and \nws\n settings but there are situations\nwhere repetitions should not pass the end of the current line. For this feature\n\neolterm\n parameter is introduced which can be set on a repetition and will\nensure that it terminates before entering a new line.\n\n\ndef grammar():      return first, second\ndef first():        return ZeroOrMore([\"a\", \"b\"], eolterm=True)\ndef second():       return \"a\"\n\n# first rule should match only first line\n# so that second rule will match \"a\" on the new line\ninput = \"\"\"a a b a b b\na\"\"\"\n\nparser = ParserPython(grammar)\nresult = parser.parse(input)",
            "title": "Parser configuration"
        },
        {
            "location": "/configuration/#parser-configuration",
            "text": "This section describes how to alter parser default behaviour.   There are some aspect of parsing that can be configured using parser and/or ParsingExpression  parameters.  Arpeggio has some sane default behaviour but\ngives the user possibility to alter it.  This section describes various parser parameters.",
            "title": "Parser configuration"
        },
        {
            "location": "/configuration/#case-insensitive-parsing",
            "text": "By default Arpeggio is case sensitive. If you wish to do case insensitive\nparsing set parser parameter  ignore_case  to  True .  parser = ParserPython(calc, ignore_case=True)",
            "title": "Case insensitive parsing"
        },
        {
            "location": "/configuration/#white-space-handling",
            "text": "Arpeggio by default skips white-spaces. You can change this behaviour with the\nparameter  skipws  given to parser constructor.  parser = ParserPython(calc, skipws=False)  You can also change what is considered a whitespace by Arpeggio using the  ws \nparameter. It is a plain string that consists of white-space characters. By\ndefault it is set to  \"\\t\\n\\r \" .  For example, to prevent a newline to be treated as whitespace you could write:  parser = ParserPython(calc, ws='\\t\\r ')   Note  These parameters can be used on the  Sequence  level so one could write\ngrammar like this:  def grammar():     return Sequence(\"one\", \"two\", \"three\",\n                                   skipws=False), \"four\"\nparser = ParserPython(grammar)",
            "title": "White-space handling"
        },
        {
            "location": "/configuration/#keyword-handling",
            "text": "By setting a  autokwd  parameter to  True  a word boundary match for\nkeyword-like matches will be performed.  This parameter is disabled by default.    def grammar():     return \"one\", \"two\", \"three\"\n\n  parser = ParserPython(grammar, autokwd=True)\n\n  # If autokwd is enabled this should parse without error.\n  parser.parse(\"one two three\")\n\n  # But this will not parse as the match is done using word boundaries\n  # so this is considered a one word.\n  parser.parse(\"onetwothree\")",
            "title": "Keyword handling"
        },
        {
            "location": "/configuration/#comment-handling",
            "text": "Support for comments in your language can be specified as another set of grammar\nrules.  See  simple.py example .  Parser is constructed using two parameters.  parser = ParserPython(simpleLanguage, comment)  First parameter is the root rule of main parse model while the second is a rule\nfor comments.  During parsing comment parse trees are kept in the separate list thus comments\nwill not show in the main parse tree.",
            "title": "Comment handling"
        },
        {
            "location": "/configuration/#parse-tree-reduction",
            "text": "Non-terminals are by default created for each rule. Sometimes it can result in\ntrees of great depth.  You can alter this behaviour setting  reduce_tree \nparameter to  True .  parser = ParserPython(calc, reduce_tree=True)  In this configuration non-terminals with single child will be removed from the\nparse tree.  For example,  calc  parse tree above will look like this:   Notice the removal of each non-terminal with single child.   Warning  Be aware that  semantic analysis  operates on nodes of\nfinished parse tree. Therefore, it you use  tree\nreduction  visitor methods will not\nget called for the removed nodes.",
            "title": "Parse tree reduction"
        },
        {
            "location": "/configuration/#newline-termination-for-repetitions",
            "text": "By default  Repetition  parsing expressions (i.e.  ZeroOrMore  and OneOrMore ) will obey  skipws  and  ws  settings but there are situations\nwhere repetitions should not pass the end of the current line. For this feature eolterm  parameter is introduced which can be set on a repetition and will\nensure that it terminates before entering a new line.  def grammar():      return first, second\ndef first():        return ZeroOrMore([\"a\", \"b\"], eolterm=True)\ndef second():       return \"a\"\n\n# first rule should match only first line\n# so that second rule will match \"a\" on the new line\ninput = \"\"\"a a b a b b\na\"\"\"\n\nparser = ParserPython(grammar)\nresult = parser.parse(input)",
            "title": "Newline termination for Repetitions"
        },
        {
            "location": "/semantics/",
            "text": "Semantic analysis - Visitors\n\n\nThis section explains how to transform parse tree to a more usable structure.\n\n\n\n\nYou will surely always want to extract some information from the parse tree or\nto transform it in some more usable form.  The process of parse tree\ntransformation to other forms is referred to as \nsemantic analysis\n.  You could\ndo that using parse tree navigation etc. but it is better to use some standard\nmechanism.\n\n\nIn Arpeggio a visitor pattern is used for semantic analysis. You write a python\nclass that inherits \nPTNodeVisitor\n and has a methods of the form\n\nvisit_<rule name>(self, node, children)\n where rule name is a rule name from\nthe grammar.\n\n\nclass CalcVisitor(PTNodeVisitor):\n\n    def visit_number(self, node, children):\n        return float(node.value)\n\n    def visit_factor(self, node, children):\n        if len(children) == 1:\n            return children[0]\n        sign = -1 if children[0] == '-' else 1\n        return sign * children[-1]\n\n    ...\n\n\n\nDuring a semantic analysis a parse tree is walked in the depth-first manner and\nfor each node a proper visitor method is called to transform it to some other\nform. The results are than fed to the parent node visitor method.  This is\nrepeated until the final, top level parse tree node is processed (its visitor is\ncalled). The result of the top level node is the final output of the semantic\nanalysis.\n\n\nTo run semantic analysis apply your visitor class to the parse tree using\n\nvisit_parse_tree\n function.\n\n\nresult = visit_parse_tree(parse_tree, CalcVisitor(debug=True))\n\n\n\n\nThe first parameter is a parse tree you get from the \nparser.parse\n call while\nthe second parameter is an instance of your visitor class. Semantic analysis can\nbe run in debug mode if you set \ndebug\n parameter to \nTrue\n during visitor\nconstruction. You can use this flag to print your own debug information from\nvisitor methods.\n\n\nclass MyLanguageVisitor(PTNodeVisitor):\n\n  def visit_somerule(self, node, children):\n    if self.debug:\n      print(\"Visiting some rule!\")\n\n\n\nDuring semantic analysis, each \nvisitor_xxx\n method gets current parse tree node\nas the \nnode\n parameter and the evaluated children nodes as the \nchildren\n\nparameter.\n\n\nFor example, if you have \nexpression\n rule in your grammar than the\ntransformation of the non-terminal matched by this rule can be done as:\n\n\ndef visitor_expression(self, node, children):\n  ... # transform node using 'node' and 'children' parameter\n  return transformed_node\n\n\n\nnode\n is the current \nNonTerminal\n or \nTerminal\n from the parse tree\nwhile the \nchildren\n is instance of \nSemanticResults\n class.  This class is\na list-like structure that holds the results of semantic evaluation from the\nchildren parse tree nodes (analysis is done bottom-up).\n\n\nTo suppress node completely return \nNone\n from visitor method. In this case\nthe parent visitor method will not get this node in its \nchildren\n parameter.\n\n\nIn the \ncalc.py\nexample\n\na semantic analysis (\nCalcVisitor\n class) will evaluate the result of arithmetic\nexpression. The parse tree is thus transformed to a single numeric value that\nrepresent the result of the expression.\n\n\nIn the \nrobot.py\nexample\n\na semantic analysis (\nRobotVisitor\n class) will evaluate robot program\n(transform its parse tree) to the final robot location.\n\n\nSemantic analysis can do a complex stuff. For example, see\n\npeg_peg.py\n\nand\n\nPEGVisitor\n\nclass where the PEG parser for the given language is built using semantic\nanalysis.\n\n\nSemanticActionResults\n\n\nClass of object returned from the parse tree nodes evaluation. Used for\nfiltering and navigation over evaluation results on children nodes.\n\n\nInstance of this class is given as \nchildren`` parameter of\nvisitor_xxx\nmethods.  This class inherits\nlist` so index access as well as iteration is\navailable.\n\n\nFurthermore, child nodes can be filtered by rule name using name lookup.\n\n\ndef visit_bar(self, node, children):\n  # Index access\n  child = children[2]\n\n  # Iteration\n  for child in children:\n    ...\n\n  # Rule name lookup\n  # Returns a list of all rules created by PEG rule 'baz'\n  baz_created = children['baz']\n\n\n\n\nPost-processing in second calls\n\n\nVisitor may define method with the \nsecond_<rule_name>\n name form. If this\nmethod exists it will be called after all parse tree node are processed and it\nwill be given the results of the \nvisitor_<rule_name>\n call.\n\n\nThis is usually used when some additional post-processing is needed (e.g.\nreference resolving).\n\n\nDefault actions\n\n\nFor each parse tree node that does not have an appropriate \nvisitor_xxx\n\nmethod a default action is performed.  If the node is created by a plain string\nmatch action will return \nNone\n and thus suppress this node. This is handy\nfor all those syntax noise (bracket, braces, keywords etc.).\n\n\nFor example, if your grammar is:\n\n\nnumber_in_brackets = \"(\" number \")\"\nnumber = r'\\d+'\n\n\n\n\nThan the default action for \nnumber\n will return number converted to a string\nand the default action for \n(\n and \n)\n will return \nNone\n and thus suppress this\nnodes so the visitor method for \nnumber_in_brackets\n rule will only see one\nchild (from the \nnumber\n rule reference).\n\n\nIf the node is a non-terminal and there is only one child the default action\nwill return that child effectively passing it to the parent node visitor.\n\n\nDefault actions can be disabled by setting parameter \ndefaults\n to \nFalse\n on\nvisitor construction.\n\n\nresult = visit_parse_tree(parse_tree, CalcVisitor(defaults=False))\n\n\n\n\nIf you want to call this default behaviour from your visitor method call\n\nvisit__default__(node, children)\n on superclass (\nPTNodeVisitor\n).\n\n\ndef visitor_myrule(self, node, children):\n  if some_condition:\n    ...\n  else:\n    return super(MyVisitor, self).visit__default__(node, children)",
            "title": "Semantic analysis"
        },
        {
            "location": "/semantics/#semantic-analysis-visitors",
            "text": "This section explains how to transform parse tree to a more usable structure.   You will surely always want to extract some information from the parse tree or\nto transform it in some more usable form.  The process of parse tree\ntransformation to other forms is referred to as  semantic analysis .  You could\ndo that using parse tree navigation etc. but it is better to use some standard\nmechanism.  In Arpeggio a visitor pattern is used for semantic analysis. You write a python\nclass that inherits  PTNodeVisitor  and has a methods of the form visit_<rule name>(self, node, children)  where rule name is a rule name from\nthe grammar.  class CalcVisitor(PTNodeVisitor):\n\n    def visit_number(self, node, children):\n        return float(node.value)\n\n    def visit_factor(self, node, children):\n        if len(children) == 1:\n            return children[0]\n        sign = -1 if children[0] == '-' else 1\n        return sign * children[-1]\n\n    ...  During a semantic analysis a parse tree is walked in the depth-first manner and\nfor each node a proper visitor method is called to transform it to some other\nform. The results are than fed to the parent node visitor method.  This is\nrepeated until the final, top level parse tree node is processed (its visitor is\ncalled). The result of the top level node is the final output of the semantic\nanalysis.  To run semantic analysis apply your visitor class to the parse tree using visit_parse_tree  function.  result = visit_parse_tree(parse_tree, CalcVisitor(debug=True))  The first parameter is a parse tree you get from the  parser.parse  call while\nthe second parameter is an instance of your visitor class. Semantic analysis can\nbe run in debug mode if you set  debug  parameter to  True  during visitor\nconstruction. You can use this flag to print your own debug information from\nvisitor methods.  class MyLanguageVisitor(PTNodeVisitor):\n\n  def visit_somerule(self, node, children):\n    if self.debug:\n      print(\"Visiting some rule!\")  During semantic analysis, each  visitor_xxx  method gets current parse tree node\nas the  node  parameter and the evaluated children nodes as the  children \nparameter.  For example, if you have  expression  rule in your grammar than the\ntransformation of the non-terminal matched by this rule can be done as:  def visitor_expression(self, node, children):\n  ... # transform node using 'node' and 'children' parameter\n  return transformed_node  node  is the current  NonTerminal  or  Terminal  from the parse tree\nwhile the  children  is instance of  SemanticResults  class.  This class is\na list-like structure that holds the results of semantic evaluation from the\nchildren parse tree nodes (analysis is done bottom-up).  To suppress node completely return  None  from visitor method. In this case\nthe parent visitor method will not get this node in its  children  parameter.  In the  calc.py\nexample \na semantic analysis ( CalcVisitor  class) will evaluate the result of arithmetic\nexpression. The parse tree is thus transformed to a single numeric value that\nrepresent the result of the expression.  In the  robot.py\nexample \na semantic analysis ( RobotVisitor  class) will evaluate robot program\n(transform its parse tree) to the final robot location.  Semantic analysis can do a complex stuff. For example, see peg_peg.py \nand PEGVisitor \nclass where the PEG parser for the given language is built using semantic\nanalysis.",
            "title": "Semantic analysis - Visitors"
        },
        {
            "location": "/semantics/#semanticactionresults",
            "text": "Class of object returned from the parse tree nodes evaluation. Used for\nfiltering and navigation over evaluation results on children nodes.  Instance of this class is given as  children`` parameter of visitor_xxx methods.  This class inherits list` so index access as well as iteration is\navailable.  Furthermore, child nodes can be filtered by rule name using name lookup.  def visit_bar(self, node, children):\n  # Index access\n  child = children[2]\n\n  # Iteration\n  for child in children:\n    ...\n\n  # Rule name lookup\n  # Returns a list of all rules created by PEG rule 'baz'\n  baz_created = children['baz']",
            "title": "SemanticActionResults"
        },
        {
            "location": "/semantics/#post-processing-in-second-calls",
            "text": "Visitor may define method with the  second_<rule_name>  name form. If this\nmethod exists it will be called after all parse tree node are processed and it\nwill be given the results of the  visitor_<rule_name>  call.  This is usually used when some additional post-processing is needed (e.g.\nreference resolving).",
            "title": "Post-processing in second calls"
        },
        {
            "location": "/semantics/#default-actions",
            "text": "For each parse tree node that does not have an appropriate  visitor_xxx \nmethod a default action is performed.  If the node is created by a plain string\nmatch action will return  None  and thus suppress this node. This is handy\nfor all those syntax noise (bracket, braces, keywords etc.).  For example, if your grammar is:  number_in_brackets = \"(\" number \")\"\nnumber = r'\\d+'  Than the default action for  number  will return number converted to a string\nand the default action for  (  and  )  will return  None  and thus suppress this\nnodes so the visitor method for  number_in_brackets  rule will only see one\nchild (from the  number  rule reference).  If the node is a non-terminal and there is only one child the default action\nwill return that child effectively passing it to the parent node visitor.  Default actions can be disabled by setting parameter  defaults  to  False  on\nvisitor construction.  result = visit_parse_tree(parse_tree, CalcVisitor(defaults=False))  If you want to call this default behaviour from your visitor method call visit__default__(node, children)  on superclass ( PTNodeVisitor ).  def visitor_myrule(self, node, children):\n  if some_condition:\n    ...\n  else:\n    return super(MyVisitor, self).visit__default__(node, children)",
            "title": "Default actions"
        },
        {
            "location": "/tutorials/csv/",
            "text": "Comma-Separated Values (CSV) parser tutorial\n\n\nA tutorial for building parser for well known CSV format.\n\n\n\n\nIn this tutorial we will see how to make a parser for a simple data interchange\nformat - \nCSV\n (Comma-Separated Values).\nCSV is a textual format for tabular data interchange. It is described by\n\nRFC 4180\n.\n\n\nHere\n is an example of\nCSV file:\n\n\nYear,Make,Model,Length\n1997,Ford,E350,2.34\n2000,Mercury,Cougar,2.38\n\n\n\n\nAlthough, there is \ncsv module\n in\nthe standard Python library this example has been made as the CSV is ubiquitous\nand easy to understand so it it a good starter for learning Arpeggio.\n\n\nThe grammar\n\n\nLet's start first by creating a python module called \ncsv.py\n.\n\n\nNow, let's define CSV grammar. \n\n\n\n\n\n\nCSV file consists of one or more records separated by a newline.\n\n\ndef csvfile():    return OneOrMore([record, '\\n']), EOF\n\n\n\n\n\n\n\nEach record consists of fields separated with commas.\n\n\ndef record():     return field, ZeroOrMore(\",\", field)\n\n\n\n\n\n\n\nEach field may be quoted or not.\n\n\ndef field():      return [quoted_field, field_content]\n\n\n\n\n\n\n\nField content is everything until newline or comma.\n\n\ndef field_content():            return _(r'([^,\\n])+')\n\n\n\nWe use regular expression to match everything that is not comma or\n  newline.\n\n\n\n\n\n\nQuoted field starts and ends with double quotes.\n\n\ndef quoted_field():             return '\"', field_content_quoted, '\"'\n\n\n\n\n\n\n\nQuoted field content is defined as \n\n\ndef field_content_quoted():     return _(r'((\"\")|([^\"]))+')\n\n\n\nQuoted field content is defined with regular expression that will match\n  everything until the closing double-quote. Double quote inside data must\n  be escaped by doubling it (\n\"\"\n).\n\n\n\n\n\n\nThe whole content of the \ncsv.py\n file until now should be:\n\n\nfrom arpeggio import *\nfrom arpeggio import RegExMatch as _\n\n# This is the CSV grammar\ndef record():                   return field, ZeroOrMore(\",\", field)\ndef field():                    return [quoted_field, field_content]\ndef quoted_field():             return '\"', field_content_quoted, '\"'\ndef field_content():            return _(r'([^,\\n])+')\ndef field_content_quoted():     return _(r'((\"\")|([^\"]))+')\ndef csvfile():                  return OneOrMore([record, '\\n']), EOF\n\n\n\nThe parser\n\n\nLet's instantiate parser. In order to catch newlines in \ncsvfile\n rule we must\ntell Arpeggio not to treat newlines as whitespace, i.e. not to skip over them.\nThus, we will be able to handle them explicitly as we do in csvfile rule. To do\nso we will use \nws\n parameter in parser construction to redefine what is\nconsidered as whitespace.  You can find more information\n\nhere\n.\n\n\nAfter the grammar in \ncsv.py\n instantiate the parser:\n\n\nparser = ParserPython(csvfile, ws='\\t ')\n\n\n\nSo, whitespace will be a tab char or a space. Newline will be treated as regular\ncharacter.  We give grammar root rule to the \nParserPython\n. In this example it\nis \ncsvfile\n function.\n\n\nparser\n now refers to the parser object capable of parsing CSV inputs.\n\n\nParsing\n\n\nLet's parse some CSV example string.\n\n\nCreate file \ntest_data.csv\n with the following content:\n\n\nUnquoted test, \"Quoted test\", 23234, One Two Three, \"343456.45\"\n\nUnquoted test 2, \"Quoted test with \"\"inner\"\" quotes\", 23234, One Two Three, \"343456.45\"\nUnquoted test 3, \"Quoted test 3\", 23234, One Two Three, \"343456.45\"\n\n\n\nIn \ncsv.py\n file write:\n\n\ntest_data = open('test_data.csv', 'r').read()\nparse_tree = parser.parse(test_data)\n\n\n\n\n\ntest_data\n is Python string containing test CSV data from the file. Calling\n\nparser.parse\n on the data will produce the \nparse tree\n.\n\n\nIf you run \ncsv.py\n module, and there are no syntax errors in the \ntest_data.csv\n\nfile, \nparse_tree\n will be a reference to \nparse tree\n of\nthe test CSV data.\n\n\n$ python csv.py\n\n\n\n\nCongratulations!! You have successfuly parsed CSV file.\n\n\nThis parse tree is \nvisualized\n below\n(Tip: The image is large. Right click on it and choose \nView image\n to see it in\na separate tab and to be able to use zooming):\n\n\n\n\n\n\nNote\n\n\nTo visualize grammar (aka parser model) and parse tree instantiate the\nparser in debug mode.\n\n\nparser = ParserPython(csvfile, ws='\\t ', debug=True)\n\n\n\nTransform generated \ndot\n files to images.\nSee more \nhere\n\n\n\n\nDefining grammar using PEG notation\n\n\nNow, let's try the same but using \ntextual PEG\nnotation\n for the grammar\ndefinition.\n\n\nWe shall repeat the process above but we shall encode rules in PEG.\nWe shall use clean PEG variant (\narpeggio.cleanpeg\n module).\n\n\nFirst, create textual file \ncsv.peg\n to store the grammar.\n\n\n\n\n\n\nCSV file consists of one or more records separated by a newline.\n\n\ncsvfile = (record / '\\n')+ EOF\n\n\n\n\n\n\n\nEach record consists of fields separated with commas.\n\n\nrecord = field (\",\" field)*\n\n\n\n\n\n\n\nEach field may be quoted or not.\n\n\nfield = quoted_field / field_content\n\n\n\n\n\n\n\nField content is everything until newline or comma.\n\n\nfield_content = r'([^,\\n])+'\n\n\n\nWe use regular expression to match everything that is not comma or\n  newline.\n\n\n\n\n\n\nQuoted field starts and ends with double quotes.\n\n\nquoted_field = '\"' field_content_quoted '\"'\n\n\n\n\n\n\n\nQuoted field content is defined as \n\n\nfield_content_quoted = r'((\"\")|([^\"]))+'\n\n\n\nQuoted field content is defined with regular expression that will match\n  everything until the closing double-quote. Double quote inside data must\n  be escaped by doubling it (\n\"\"\n).\n\n\n\n\n\n\nThe whole grammar (i.e. the contents of \ncsv.peg\n file) is:\n\n\n  csvfile = (record / r'\\n')+ EOF\n  record = field (\",\" field)*\n  field = quoted_field / field_content\n  field_content = r'([^,\\n])+'\n  quoted_field = '\"' field_content_quoted '\"'\n  field_content_quoted = r'((\"\")|([^\"]))+'\n\n\n\nNow, we shall create \ncsv_peg.py\n file in order to instantiate our parser and\nparse inputs.  This time we shall instantiate different parser class\n(\nParserPEG\n). The whole content of \ncsv_peg.py\n should be:\n\n\nfrom arpeggio.cleanpeg import ParserPEG\n\ncsv_grammar = open('csv.peg', 'r').read()\nparser = ParserPEG(csv_grammar, 'csvfile', ws='\\t ')\n\n\n\n\nHere we load the grammar from \ncsv.peg\n file and construct the parser using\n\nParserPEG\n class.\n\n\nThe rest of the code is the same as in \ncsv.py\n. We load \ntest_data.csv\n and\ncall \nparser.parse\n on it to produce parse tree.\n\n\nTo verify that everything works without errors execute \ncsv_peg.py\n module.\n\n\n$ python csv_peg.py\n\n\n\n\nIf we put the parser in debug mode and generate parse tree image we can \nverify that we are getting the same parse tree regardless of the grammar\nspecification approach we use.\n\n\nTo put parser in debug mode add \ndebug=True\n to the parser parameters list.\n\n\nparser = ParserPEG(csv_grammar, 'csvfile', ws='\\t ', debug=True)\n\n\n\n\nExtract data\n\n\nOur main goal is to extract data from the \ncsv\n file.\n\n\nThe parse tree we get as a result of parsing is not very useful on its own.\nWe need to transform it to some other data structure that we can use.\n\n\nFirst lets define our target data structure we want to get.\n\n\nSince \ncsv\n consists of list of records where each record consists of fields\nwe shall construct python list of lists:\n\n\n  [\n    [field1, field2, field3, ...],  # First row\n    [field1, field2, field3,...],   # Second row\n    [...],  # ...\n    ...\n  ]\n\n\n\nTo construct this list of list we may process parse tree by navigating its\nnodes and building the required target data structure.\nBut, it is easier to use Arpeggio's support for \nsemantic analysis - Visitor\nPattern\n.\n\n\nLet's make a Visitor for CSV that will build our list of lists.\n\n\nclass CSVVisitor(PTNodeVisitor):\n    def visit_record(self, node, children):\n        # record is a list of fields. The children nodes are fields so just\n        # transform it to python list.\n        return list(children)\n\n    def visit_csvfile(self, node, children):\n        # We are not interested in empty lines so we will filter them.\n        return [x for x in children if x!='\\n']\n\n\n\n\nand apply this visitor to the parse tree:\n\n\ncsv_content = visit_parse_tree(parse_tree, CSVVisitor())\n\n\n\n\nNow if we print \ncsv_content\n we can see that it is exactly what we wanted:\n\n\n[[u'Unquoted test', u'Quoted test', u'23234', u'One Two Three', u'343456.45'], [u'Unquoted test 2', u'Quoted test with \"\"inner\"\" quotes', u'23234', u'One Two Three', u'34312.7'], [u'Unquoted test 3', u'Quoted test 3', u'23234', u'One Two Three', u'343486.12']]\n\n\n\n\nBut, there is more we can do. If we look at our data we can see that some fields\nare of numeric type but they end up as strings in our target structure. Let's\nconvert them to Python floats or ints.  To do this conversion we will introduce\n\nvisit_field\n method in our \nCSVVisitor\n class.\n\n\nclass CSVVisitor(PTNodeVisitor):\n  ...\n  def visit_field(self, node, children):\n      value = children[0]\n      try:\n          return float(value)\n      except:\n          pass\n      try:\n          return int(value)\n      except:\n          return value\n  ...\n\n\n\n\nIf we print \ncsv_content\n now we can see that numeric values are not strings\nanymore but a proper Python types.\n\n\n[[u'Unquoted test', u'Quoted test', 23234.0, u'One Two Three', 343456.45], [u'Unquoted test 2', u'Quoted test with \"\"inner\"\" quotes', 23234.0, u'One Two Three', 34312.7], [u'Unquoted test 3', u'Quoted test 3', 23234.0, u'One Two Three', 343486.12]]\n\n\n\n\nThis example code can be found \nhere\n.",
            "title": "CSV"
        },
        {
            "location": "/tutorials/csv/#comma-separated-values-csv-parser-tutorial",
            "text": "A tutorial for building parser for well known CSV format.   In this tutorial we will see how to make a parser for a simple data interchange\nformat -  CSV  (Comma-Separated Values).\nCSV is a textual format for tabular data interchange. It is described by RFC 4180 .  Here  is an example of\nCSV file:  Year,Make,Model,Length\n1997,Ford,E350,2.34\n2000,Mercury,Cougar,2.38  Although, there is  csv module  in\nthe standard Python library this example has been made as the CSV is ubiquitous\nand easy to understand so it it a good starter for learning Arpeggio.",
            "title": "Comma-Separated Values (CSV) parser tutorial"
        },
        {
            "location": "/tutorials/csv/#the-grammar",
            "text": "Let's start first by creating a python module called  csv.py .  Now, let's define CSV grammar.     CSV file consists of one or more records separated by a newline.  def csvfile():    return OneOrMore([record, '\\n']), EOF    Each record consists of fields separated with commas.  def record():     return field, ZeroOrMore(\",\", field)    Each field may be quoted or not.  def field():      return [quoted_field, field_content]    Field content is everything until newline or comma.  def field_content():            return _(r'([^,\\n])+')  We use regular expression to match everything that is not comma or\n  newline.    Quoted field starts and ends with double quotes.  def quoted_field():             return '\"', field_content_quoted, '\"'    Quoted field content is defined as   def field_content_quoted():     return _(r'((\"\")|([^\"]))+')  Quoted field content is defined with regular expression that will match\n  everything until the closing double-quote. Double quote inside data must\n  be escaped by doubling it ( \"\" ).    The whole content of the  csv.py  file until now should be:  from arpeggio import *\nfrom arpeggio import RegExMatch as _\n\n# This is the CSV grammar\ndef record():                   return field, ZeroOrMore(\",\", field)\ndef field():                    return [quoted_field, field_content]\ndef quoted_field():             return '\"', field_content_quoted, '\"'\ndef field_content():            return _(r'([^,\\n])+')\ndef field_content_quoted():     return _(r'((\"\")|([^\"]))+')\ndef csvfile():                  return OneOrMore([record, '\\n']), EOF",
            "title": "The grammar"
        },
        {
            "location": "/tutorials/csv/#the-parser",
            "text": "Let's instantiate parser. In order to catch newlines in  csvfile  rule we must\ntell Arpeggio not to treat newlines as whitespace, i.e. not to skip over them.\nThus, we will be able to handle them explicitly as we do in csvfile rule. To do\nso we will use  ws  parameter in parser construction to redefine what is\nconsidered as whitespace.  You can find more information here .  After the grammar in  csv.py  instantiate the parser:  parser = ParserPython(csvfile, ws='\\t ')  So, whitespace will be a tab char or a space. Newline will be treated as regular\ncharacter.  We give grammar root rule to the  ParserPython . In this example it\nis  csvfile  function.  parser  now refers to the parser object capable of parsing CSV inputs.",
            "title": "The parser"
        },
        {
            "location": "/tutorials/csv/#parsing",
            "text": "Let's parse some CSV example string.  Create file  test_data.csv  with the following content:  Unquoted test, \"Quoted test\", 23234, One Two Three, \"343456.45\"\n\nUnquoted test 2, \"Quoted test with \"\"inner\"\" quotes\", 23234, One Two Three, \"343456.45\"\nUnquoted test 3, \"Quoted test 3\", 23234, One Two Three, \"343456.45\"  In  csv.py  file write:  test_data = open('test_data.csv', 'r').read()\nparse_tree = parser.parse(test_data)  test_data  is Python string containing test CSV data from the file. Calling parser.parse  on the data will produce the  parse tree .  If you run  csv.py  module, and there are no syntax errors in the  test_data.csv \nfile,  parse_tree  will be a reference to  parse tree  of\nthe test CSV data.  $ python csv.py  Congratulations!! You have successfuly parsed CSV file.  This parse tree is  visualized  below\n(Tip: The image is large. Right click on it and choose  View image  to see it in\na separate tab and to be able to use zooming):    Note  To visualize grammar (aka parser model) and parse tree instantiate the\nparser in debug mode.  parser = ParserPython(csvfile, ws='\\t ', debug=True)  Transform generated  dot  files to images.\nSee more  here",
            "title": "Parsing"
        },
        {
            "location": "/tutorials/csv/#defining-grammar-using-peg-notation",
            "text": "Now, let's try the same but using  textual PEG\nnotation  for the grammar\ndefinition.  We shall repeat the process above but we shall encode rules in PEG.\nWe shall use clean PEG variant ( arpeggio.cleanpeg  module).  First, create textual file  csv.peg  to store the grammar.    CSV file consists of one or more records separated by a newline.  csvfile = (record / '\\n')+ EOF    Each record consists of fields separated with commas.  record = field (\",\" field)*    Each field may be quoted or not.  field = quoted_field / field_content    Field content is everything until newline or comma.  field_content = r'([^,\\n])+'  We use regular expression to match everything that is not comma or\n  newline.    Quoted field starts and ends with double quotes.  quoted_field = '\"' field_content_quoted '\"'    Quoted field content is defined as   field_content_quoted = r'((\"\")|([^\"]))+'  Quoted field content is defined with regular expression that will match\n  everything until the closing double-quote. Double quote inside data must\n  be escaped by doubling it ( \"\" ).    The whole grammar (i.e. the contents of  csv.peg  file) is:    csvfile = (record / r'\\n')+ EOF\n  record = field (\",\" field)*\n  field = quoted_field / field_content\n  field_content = r'([^,\\n])+'\n  quoted_field = '\"' field_content_quoted '\"'\n  field_content_quoted = r'((\"\")|([^\"]))+'  Now, we shall create  csv_peg.py  file in order to instantiate our parser and\nparse inputs.  This time we shall instantiate different parser class\n( ParserPEG ). The whole content of  csv_peg.py  should be:  from arpeggio.cleanpeg import ParserPEG\n\ncsv_grammar = open('csv.peg', 'r').read()\nparser = ParserPEG(csv_grammar, 'csvfile', ws='\\t ')  Here we load the grammar from  csv.peg  file and construct the parser using ParserPEG  class.  The rest of the code is the same as in  csv.py . We load  test_data.csv  and\ncall  parser.parse  on it to produce parse tree.  To verify that everything works without errors execute  csv_peg.py  module.  $ python csv_peg.py  If we put the parser in debug mode and generate parse tree image we can \nverify that we are getting the same parse tree regardless of the grammar\nspecification approach we use.  To put parser in debug mode add  debug=True  to the parser parameters list.  parser = ParserPEG(csv_grammar, 'csvfile', ws='\\t ', debug=True)",
            "title": "Defining grammar using PEG notation"
        },
        {
            "location": "/tutorials/csv/#extract-data",
            "text": "Our main goal is to extract data from the  csv  file.  The parse tree we get as a result of parsing is not very useful on its own.\nWe need to transform it to some other data structure that we can use.  First lets define our target data structure we want to get.  Since  csv  consists of list of records where each record consists of fields\nwe shall construct python list of lists:    [\n    [field1, field2, field3, ...],  # First row\n    [field1, field2, field3,...],   # Second row\n    [...],  # ...\n    ...\n  ]  To construct this list of list we may process parse tree by navigating its\nnodes and building the required target data structure.\nBut, it is easier to use Arpeggio's support for  semantic analysis - Visitor\nPattern .  Let's make a Visitor for CSV that will build our list of lists.  class CSVVisitor(PTNodeVisitor):\n    def visit_record(self, node, children):\n        # record is a list of fields. The children nodes are fields so just\n        # transform it to python list.\n        return list(children)\n\n    def visit_csvfile(self, node, children):\n        # We are not interested in empty lines so we will filter them.\n        return [x for x in children if x!='\\n']  and apply this visitor to the parse tree:  csv_content = visit_parse_tree(parse_tree, CSVVisitor())  Now if we print  csv_content  we can see that it is exactly what we wanted:  [[u'Unquoted test', u'Quoted test', u'23234', u'One Two Three', u'343456.45'], [u'Unquoted test 2', u'Quoted test with \"\"inner\"\" quotes', u'23234', u'One Two Three', u'34312.7'], [u'Unquoted test 3', u'Quoted test 3', u'23234', u'One Two Three', u'343486.12']]  But, there is more we can do. If we look at our data we can see that some fields\nare of numeric type but they end up as strings in our target structure. Let's\nconvert them to Python floats or ints.  To do this conversion we will introduce visit_field  method in our  CSVVisitor  class.  class CSVVisitor(PTNodeVisitor):\n  ...\n  def visit_field(self, node, children):\n      value = children[0]\n      try:\n          return float(value)\n      except:\n          pass\n      try:\n          return int(value)\n      except:\n          return value\n  ...  If we print  csv_content  now we can see that numeric values are not strings\nanymore but a proper Python types.  [[u'Unquoted test', u'Quoted test', 23234.0, u'One Two Three', 343456.45], [u'Unquoted test 2', u'Quoted test with \"\"inner\"\" quotes', 23234.0, u'One Two Three', 34312.7], [u'Unquoted test 3', u'Quoted test 3', 23234.0, u'One Two Three', 343486.12]]  This example code can be found  here .",
            "title": "Extract data"
        },
        {
            "location": "/tutorials/bibtex/",
            "text": "BibTex tutorial\n\n\nA tutorial for parsing well known format for bibliographic references.\n\n\n\n\n\n\nTODO\n\n\nThis tutorial will be based on \nBibTex example\n.",
            "title": "BibTex"
        },
        {
            "location": "/tutorials/bibtex/#bibtex-tutorial",
            "text": "A tutorial for parsing well known format for bibliographic references.    TODO  This tutorial will be based on  BibTex example .",
            "title": "BibTex tutorial"
        },
        {
            "location": "/tutorials/calc/",
            "text": "Calculator tutorial\n\n\nA tutorial for parsing of arithmetic expressions.\n\n\n\n\n\n\nTODO\n\n\nThis tutorial will be based on \nCalc example\n.\n\n\n\n\nIn this tutorial we will make a parser and evaluator for simple arithmetic expression\n(numbers and operations - addition, substraction, multiplication and division).\nThe parser will be able to recognize following expressions:\n\n\n2+7-3.6\n3/(3-1)+45*2.17+8\n4*12+5-4*(2-8)\n...\n\n\n\nEvaluation will be done using \nsupport for semantic analysis\n\n\nLet's start with grammar definition first. Expression parsing has additional",
            "title": "Calc"
        },
        {
            "location": "/tutorials/calc/#calculator-tutorial",
            "text": "A tutorial for parsing of arithmetic expressions.    TODO  This tutorial will be based on  Calc example .   In this tutorial we will make a parser and evaluator for simple arithmetic expression\n(numbers and operations - addition, substraction, multiplication and division).\nThe parser will be able to recognize following expressions:  2+7-3.6\n3/(3-1)+45*2.17+8\n4*12+5-4*(2-8)\n...  Evaluation will be done using  support for semantic analysis  Let's start with grammar definition first. Expression parsing has additional",
            "title": "Calculator tutorial"
        },
        {
            "location": "/about/discuss/",
            "text": "Discuss, ask questions\n\n\nIf you want to get help or involve in the community.\n\n\n\n\nPlease use \ndiscussion\nforum\n for general\ndiscussions, suggestions etc.\n\n\nIf you are on \nstackoverflow\n you can ask questions\nthere.  Just make sure to tag your question with \narpeggio\n so that your\nquestion reach me.",
            "title": "Discuss"
        },
        {
            "location": "/about/discuss/#discuss-ask-questions",
            "text": "If you want to get help or involve in the community.   Please use  discussion\nforum  for general\ndiscussions, suggestions etc.  If you are on  stackoverflow  you can ask questions\nthere.  Just make sure to tag your question with  arpeggio  so that your\nquestion reach me.",
            "title": "Discuss, ask questions"
        },
        {
            "location": "/about/contributing/",
            "text": "Contributions\n\n\nIf you want to contribute to the Arpeggio project.\n\n\n\n\nArpeggio is open for contributions. You can contribute code, documentation,\ntests, bug reports.  If you plan to make a contribution it would be great if you\nfirst announce that on the discussion forum.\n\n\nFor bug reports please use github \nissue tracker\n.\n\n\nFor code/doc/test contributions do the following:\n\n\n\n\nFork the \nproject on github\n.\n\n\n\n\nClone your fork.\n\n\nTo clone source repository with git and install for development do:\n\n\n$ git clone git@github.com:your_user_name/Arpeggio.git\n$ cd Arpeggio\n$ python setup.py develop\n\n\n\n\n\n\n\nMake a branch for the new feature and switch to it.\n\n\n\n\nMake one or more commits.\n\n\nPush your branch to github.\n\n\nMake a pull request. I will look at the changes and if everything is ok I will pull it in.\n\n\n\n\n\n\nNote\n\n\nFor code contributions please try to adhere to the \nPEP-8 guidelines\n.\nAlthough I am not strict in that regard it is useful to have a common ground for\ncoding style. To make things easier use tools for code checking (PyLint,\nPyFlakes, pep8 etc.).",
            "title": "Contributing"
        },
        {
            "location": "/about/contributing/#contributions",
            "text": "If you want to contribute to the Arpeggio project.   Arpeggio is open for contributions. You can contribute code, documentation,\ntests, bug reports.  If you plan to make a contribution it would be great if you\nfirst announce that on the discussion forum.  For bug reports please use github  issue tracker .  For code/doc/test contributions do the following:   Fork the  project on github .   Clone your fork.  To clone source repository with git and install for development do:  $ git clone git@github.com:your_user_name/Arpeggio.git\n$ cd Arpeggio\n$ python setup.py develop    Make a branch for the new feature and switch to it.   Make one or more commits.  Push your branch to github.  Make a pull request. I will look at the changes and if everything is ok I will pull it in.    Note  For code contributions please try to adhere to the  PEP-8 guidelines .\nAlthough I am not strict in that regard it is useful to have a common ground for\ncoding style. To make things easier use tools for code checking (PyLint,\nPyFlakes, pep8 etc.).",
            "title": "Contributions"
        },
        {
            "location": "/about/license/",
            "text": "Arpeggio is released under the terms of the MIT License\n\n\nCopyright (c) 2009-2015 Igor R. Dejanovi\u0107 \n\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.",
            "title": "License"
        }
    ]
}